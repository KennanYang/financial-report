#!/usr/bin/env python3
"""
AI+MCPé›†æˆæ¼”ç¤º - å±•ç¤ºAIæ¨¡å‹ä¸MCPå·¥å…·çš„å®Œç¾ç»“åˆ

è¿™ä¸ªæ–‡ä»¶æ¼”ç¤ºäº†å¦‚ä½•å°†AIæ¨¡å‹ï¼ˆOllama deepseek-r1ï¼‰ä¸MCPå·¥å…·ç»“åˆä½¿ç”¨ï¼Œ
ç”Ÿæˆæ™ºèƒ½çš„è´¢åŠ¡åˆ†æå’ŒæŠ¥å‘Šã€‚
"""

import asyncio
import json
import os
import sys
from pathlib import Path
from typing import Any, Dict, List, Optional

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent / "src"))

from mcp_server.tools.ai_enhanced_report_generator import AIEnhancedReportGenerator
from mcp_server.tools.ollama_client import OllamaClient
from mcp.types import CallToolRequest, CallToolResult, TextContent


class AIMCPDemo:
    """AI+MCPé›†æˆæ¼”ç¤ºç±»"""
    
    def __init__(self, openai_api_key: Optional[str] = None, 
                 ollama_url: str = "http://localhost:11434",
                 ollama_model: str = "deepseek-r1:7b"):
        """
        åˆå§‹åŒ–AI+MCPé›†æˆæ¼”ç¤º
        
        Args:
            openai_api_key: OpenAI APIå¯†é’¥ï¼ˆå¯é€‰ï¼‰
            ollama_url: OllamaæœåŠ¡URL
            ollama_model: Ollamaæ¨¡å‹åç§°
        """
        self.openai_api_key = openai_api_key or os.getenv("OPENAI_API_KEY")
        self.ollama_url = ollama_url
        self.ollama_model = ollama_model
        
        # åˆå§‹åŒ–AIå·¥å…·
        self.ai_tool = AIEnhancedReportGenerator(
            api_key=self.openai_api_key,
            ollama_url=self.ollama_url,
            ollama_model=self.ollama_model,
            use_ollama=True
        )
        
        print(f"ğŸ¤– AI+MCPé›†æˆæ¼”ç¤ºåˆå§‹åŒ–å®Œæˆ")
        print(f"   - OpenAI API: {'âœ… å·²é…ç½®' if self.openai_api_key else 'âŒ æœªé…ç½®'}")
        print(f"   - Ollama URL: {self.ollama_url}")
        print(f"   - Ollama Model: {self.ollama_model}")
        print()
    
    async def demonstrate_ai_capabilities(self):
        """æ¼”ç¤ºAIåŠŸèƒ½"""
        print("ğŸš€ AI+MCPé›†æˆåŠŸèƒ½æ¼”ç¤º")
        print("=" * 60)
        
        # 1. æ£€æŸ¥OllamaæœåŠ¡çŠ¶æ€
        await self._check_ollama_health()
        
        # 2. è·å–å¯ç”¨å·¥å…·åˆ—è¡¨
        await self._show_available_tools()
        
        # 3. æ¼”ç¤ºAIå…¬å¸åˆ†æ
        await self._demo_ai_company_analysis()
        
        # 4. æ¼”ç¤ºAIæŠ¥å‘Šç”Ÿæˆ
        await self._demo_ai_report_generation()
        
        # 5. æ¼”ç¤ºAIæŠ•èµ„å»ºè®®
        await self._demo_ai_investment_advice()
        
        # 6. æ¼”ç¤ºAIä¸MCPå·¥å…·åä½œ
        await self._demo_ai_mcp_collaboration()
        
        print("\nğŸ‰ AI+MCPé›†æˆæ¼”ç¤ºå®Œæˆ!")
    
    async def _check_ollama_health(self):
        """æ£€æŸ¥OllamaæœåŠ¡çŠ¶æ€"""
        print("ğŸ” æ£€æŸ¥OllamaæœåŠ¡çŠ¶æ€...")
        print("-" * 40)
        
        try:
            if self.ai_tool.ollama_client:
                is_healthy = await self.ai_tool.ollama_client.health_check()
                if is_healthy:
                    print("âœ… OllamaæœåŠ¡æ­£å¸¸ï¼Œdeepseek-r1:7bæ¨¡å‹å¯ç”¨")
                    print("ğŸ’¡ å°†ä½¿ç”¨AIå¢å¼ºåŠŸèƒ½ç”ŸæˆæŠ¥å‘Š")
                else:
                    print("âš ï¸  OllamaæœåŠ¡ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨æ¨¡æ‹ŸAIåŠŸèƒ½")
            else:
                print("âš ï¸  Ollamaå®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
        except Exception as e:
            print(f"âŒ OllamaæœåŠ¡æ£€æŸ¥å¤±è´¥: {e}")
            print("ğŸ’¡ å°†ä½¿ç”¨æ¨¡æ‹ŸAIåŠŸèƒ½")
        
        print()
    
    async def _show_available_tools(self):
        """æ˜¾ç¤ºå¯ç”¨çš„AIå·¥å…·"""
        print("ğŸ“‹ å¯ç”¨çš„AIå¢å¼ºå·¥å…·:")
        print("-" * 40)
        
        try:
            from mcp.types import ListToolsRequest
            tools_result = await self.ai_tool.list_tools(ListToolsRequest(method="tools/list"))
            
            for tool in tools_result.tools:
                print(f"  ğŸ”§ {tool.name}: {tool.description}")
                if tool.inputSchema and "properties" in tool.inputSchema:
                    props = tool.inputSchema["properties"]
                    for prop_name, prop_info in props.items():
                        desc = prop_info.get("description", "")
                        required = "ï¼ˆå¿…éœ€ï¼‰" if prop_name in tool.inputSchema.get("required", []) else "ï¼ˆå¯é€‰ï¼‰"
                        print(f"    - {prop_name}: {desc} {required}")
                print()
                
        except Exception as e:
            print(f"âŒ è·å–å·¥å…·åˆ—è¡¨å¤±è´¥: {e}")
            print("ğŸ’¡ å°†ä½¿ç”¨æ¨¡æ‹Ÿæ¼”ç¤º...")
    
    async def _demo_ai_company_analysis(self):
        """æ¼”ç¤ºAIå…¬å¸åˆ†æ"""
        print("ğŸ” æ¼”ç¤ºAIå…¬å¸åˆ†æ...")
        print("-" * 40)
        
        try:
            result = await self.ai_tool._ai_analyze_company({
                "symbol": "NVDA",
                "analysis_type": "comprehensive"
            })
            
            print("âœ… AIå…¬å¸åˆ†ææˆåŠŸ!")
            print(f"ğŸ“Š åˆ†æç»“æœé•¿åº¦: {len(result.content[0].text)} å­—ç¬¦")
            print("\nğŸ“ AIåˆ†æç»“æœé¢„è§ˆ:")
            print("-" * 30)
            
            # æ˜¾ç¤ºå‰200ä¸ªå­—ç¬¦ä½œä¸ºé¢„è§ˆ
            preview = result.content[0].text[:200]
            if len(result.content[0].text) > 200:
                preview += "..."
            print(preview)
            
        except Exception as e:
            print(f"âŒ AIå…¬å¸åˆ†æå¤±è´¥: {e}")
            print("ğŸ’¡ å°†ä½¿ç”¨æ¨¡æ‹Ÿç»“æœ...")
            
            # æ¨¡æ‹ŸAIåˆ†æç»“æœ
            mock_result = """
åŸºäºå¯¹NVIDIA (NVDA) çš„AIåˆ†æï¼Œæˆ‘å‘ç°ï¼š

1. è´¢åŠ¡è¡¨ç°å¼ºåŠ²ï¼šè¥æ”¶å’Œåˆ©æ¶¦æŒç»­å¢é•¿
2. AIèŠ¯ç‰‡éœ€æ±‚æ—ºç››ï¼šæ•°æ®ä¸­å¿ƒå’ŒAIè®­ç»ƒéœ€æ±‚æ¿€å¢
3. æŠ€æœ¯ä¼˜åŠ¿æ˜æ˜¾ï¼šåœ¨GPUé¢†åŸŸä¿æŒé¢†å…ˆåœ°ä½
4. é£é™©å› ç´ ï¼šä¾èµ–å°‘æ•°å¤§å®¢æˆ·ï¼Œç«äº‰åŠ å‰§

æŠ•èµ„å»ºè®®ï¼šé•¿æœŸçœ‹å¥½ï¼Œå»ºè®®é€‚åº¦é…ç½®
            """
            print("ğŸ¤– æ¨¡æ‹ŸAIåˆ†æç»“æœ:")
            print(mock_result)
        
        print()
    
    async def _demo_ai_report_generation(self):
        """æ¼”ç¤ºAIæŠ¥å‘Šç”Ÿæˆ"""
        print("ğŸ“Š æ¼”ç¤ºAIæŠ¥å‘Šç”Ÿæˆ...")
        print("-" * 40)
        
        try:
            result = await self.ai_tool._ai_generate_report({
                "symbol": "AAPL",
                "report_style": "professional"
            })
            
            print("âœ… AIæŠ¥å‘Šç”ŸæˆæˆåŠŸ!")
            print(f"ğŸ“„ æŠ¥å‘Šé•¿åº¦: {len(result.content[0].text)} å­—ç¬¦")
            print("\nğŸ“ AIæŠ¥å‘Šé¢„è§ˆ:")
            print("-" * 30)
            
            # æ˜¾ç¤ºå‰300ä¸ªå­—ç¬¦ä½œä¸ºé¢„è§ˆ
            preview = result.content[0].text[:300]
            if len(result.content[0].text) > 300:
                preview += "..."
            print(preview)
            
        except Exception as e:
            print(f"âŒ AIæŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
            print("ğŸ’¡ å°†ä½¿ç”¨æ¨¡æ‹Ÿç»“æœ...")
            
            # æ¨¡æ‹ŸAIæŠ¥å‘Šç»“æœ
            mock_result = """
# Apple Inc. (AAPL) ä¸“ä¸šè´¢åŠ¡åˆ†ææŠ¥å‘Š

## æ‰§è¡Œæ‘˜è¦
Apple Inc. ä½œä¸ºå…¨çƒç§‘æŠ€å·¨å¤´ï¼Œåœ¨æ™ºèƒ½æ‰‹æœºã€ä¸ªäººç”µè„‘å’ŒæœåŠ¡ä¸šåŠ¡æ–¹é¢è¡¨ç°å“è¶Šã€‚

## è´¢åŠ¡è¡¨ç°åˆ†æ
- è¥æ”¶ï¼š$394.3Bï¼ŒåŒæ¯”å¢é•¿8.1%
- å‡€åˆ©æ¶¦ï¼š$97.0Bï¼Œå‡€åˆ©æ¶¦ç‡24.6%
- ç°é‡‘æµï¼š$110.5Bï¼Œè´¢åŠ¡çŠ¶å†µç¨³å¥

## AIæŠ•èµ„å»ºè®®
åŸºäºå½“å‰è´¢åŠ¡è¡¨ç°å’Œå¸‚åœºåœ°ä½ï¼Œå»ºè®®ï¼š**ä¹°å…¥**
            """
            print("ğŸ¤– æ¨¡æ‹ŸAIæŠ¥å‘Šç»“æœ:")
            print(mock_result)
        
        print()
    
    async def _demo_ai_investment_advice(self):
        """æ¼”ç¤ºAIæŠ•èµ„å»ºè®®"""
        print("ğŸ’¡ æ¼”ç¤ºAIæŠ•èµ„å»ºè®®...")
        print("-" * 40)
        
        try:
            result = await self.ai_tool._ai_investment_advice({
                "symbol": "MSFT",
                "investment_horizon": "long_term"
            })
            
            print("âœ… AIæŠ•èµ„å»ºè®®ç”ŸæˆæˆåŠŸ!")
            print(f"ğŸ’¬ å»ºè®®é•¿åº¦: {len(result.content[0].text)} å­—ç¬¦")
            print("\nğŸ“ AIæŠ•èµ„å»ºè®®é¢„è§ˆ:")
            print("-" * 30)
            
            # æ˜¾ç¤ºå‰250ä¸ªå­—ç¬¦ä½œä¸ºé¢„è§ˆ
            preview = result.content[0].text[:250]
            if len(result.content[0].text) > 250:
                preview += "..."
            print(preview)
            
        except Exception as e:
            print(f"âŒ AIæŠ•èµ„å»ºè®®å¤±è´¥: {e}")
            print("ğŸ’¡ å°†ä½¿ç”¨æ¨¡æ‹Ÿç»“æœ...")
            
            # æ¨¡æ‹ŸAIæŠ•èµ„å»ºè®®ç»“æœ
            mock_result = """
## Microsoft (MSFT) é•¿æœŸæŠ•èµ„å»ºè®®

### æŠ•èµ„è¯„çº§ï¼šä¹°å…¥
### ç›®æ ‡ä»·æ ¼ï¼š$450
### æŠ•èµ„æœŸé™ï¼š3-5å¹´

### æ ¸å¿ƒä¼˜åŠ¿ï¼š
1. äº‘è®¡ç®—ä¸šåŠ¡å¼ºåŠ²å¢é•¿
2. AIæŠ€æœ¯é¢†å…ˆåœ°ä½
3. ç°é‡‘æµå……è£•ï¼Œåˆ†çº¢ç¨³å®š

### é£é™©æç¤ºï¼š
- ç›‘ç®¡é£é™©
- ç«äº‰åŠ å‰§
- æŠ€æœ¯å˜é©é£é™©

### å»ºè®®æ“ä½œï¼š
åˆ†æ‰¹å»ºä»“ï¼Œé•¿æœŸæŒæœ‰
            """
            print("ğŸ¤– æ¨¡æ‹ŸAIæŠ•èµ„å»ºè®®ç»“æœ:")
            print(mock_result)
        
        print()
    
    async def _demo_ai_mcp_collaboration(self):
        """æ¼”ç¤ºAIä¸MCPå·¥å…·åä½œ"""
        print("ğŸ¤ æ¼”ç¤ºAIä¸MCPå·¥å…·åä½œ...")
        print("-" * 40)
        
        print("ğŸ¯ AIå†³å®šè°ƒç”¨MCPå·¥å…·è¿›è¡Œæ•°æ®åˆ†æ...")
        
        # æ¨¡æ‹ŸAIå†³ç­–è¿‡ç¨‹
        analysis_steps = [
            "1. AIåˆ†æç”¨æˆ·éœ€æ±‚",
            "2. é€‰æ‹©åˆé€‚çš„MCPå·¥å…·",
            "3. è°ƒç”¨å·¥å…·è·å–æ•°æ®",
            "4. AIå¯¹ç»“æœè¿›è¡Œæ™ºèƒ½åˆ†æ",
            "5. ç”Ÿæˆæœ€ç»ˆå»ºè®®"
        ]
        
        for step in analysis_steps:
            print(f"   {step}")
            await asyncio.sleep(0.5)
        
        print("\nğŸ’¡ AIä¸MCPåä½œçš„ä¼˜åŠ¿:")
        print("   âœ… MCPå·¥å…·æä¾›æ ‡å‡†åŒ–æ•°æ®æ¥å£")
        print("   âœ… AIæ¨¡å‹ä¸“æ³¨äºæ™ºèƒ½åˆ†æå’Œå†³ç­–")
        print("   âœ… ä¸¤è€…ç»“åˆå®ç°1+1>2çš„æ•ˆæœ")
        print("   âœ… æ”¯æŒå¤æ‚çš„å¤šæ­¥éª¤åˆ†ææµç¨‹")
        
        print()
    
    async def start_ai_server(self):
        """å¯åŠ¨AIå¢å¼ºMCPæœåŠ¡å™¨"""
        print("ğŸš€ å¯åŠ¨AIå¢å¼ºMCPæœåŠ¡å™¨...")
        print("=" * 50)
        
        try:
            from mcp_server.server import FinancialMCPServer
            
            print("ğŸ“¡ æ­£åœ¨å¯åŠ¨æœåŠ¡å™¨...")
            server = FinancialMCPServer()
            
            print("âœ… æœåŠ¡å™¨å¯åŠ¨æˆåŠŸ!")
            print("ğŸ’¡ ç°åœ¨å¯ä»¥è¿è¡ŒAIå¢å¼ºçš„MCPæœåŠ¡äº†")
            print("ğŸ”§ æ”¯æŒçš„å·¥å…·åŒ…æ‹¬ï¼š")
            print("   - åŸºç¡€è´¢åŠ¡æŠ¥å‘Šç”Ÿæˆ")
            print("   - AIå¢å¼ºå…¬å¸åˆ†æ")
            print("   - AIæ™ºèƒ½æŠ¥å‘Šç”Ÿæˆ")
            print("   - AIæŠ•èµ„å»ºè®®")
            
            # æ³¨æ„ï¼šè¿™é‡Œåªæ˜¯æ¼”ç¤ºï¼Œå®é™…å¯åŠ¨éœ€è¦ç”¨æˆ·é€‰æ‹©
            print("\nâš ï¸  æ³¨æ„ï¼šè¿™åªæ˜¯æ¼”ç¤ºï¼Œå®é™…å¯åŠ¨è¯·è¿è¡Œï¼š")
            print("   python start_ai_server.py")
            
        except Exception as e:
            print(f"âŒ æœåŠ¡å™¨å¯åŠ¨å¤±è´¥: {e}")
            print("ğŸ’¡ è¯·æ£€æŸ¥é…ç½®æ–‡ä»¶å’Œä¾èµ–é¡¹")
        
        print()
    
    async def close(self):
        """å…³é—­AIå®¢æˆ·ç«¯"""
        if self.ai_tool:
            try:
                await self.ai_tool.close()
                print("âœ… AIå®¢æˆ·ç«¯å·²å…³é—­")
            except Exception as e:
                print(f"âŒ å…³é—­AIå®¢æˆ·ç«¯å¤±è´¥: {e}")


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ AIæ¨¡å‹ä¸MCPå·¥å…·é›†æˆæ¼”ç¤º")
    print("=" * 60)
    
    # æ£€æŸ¥ç¯å¢ƒé…ç½®
    openai_api_key = os.getenv("OPENAI_API_KEY")
    ollama_url = os.getenv("OLLAMA_URL", "http://localhost:11434")
    ollama_model = os.getenv("OLLAMA_MODEL", "deepseek-r1:7b")
    
    if not openai_api_key:
        print("âš ï¸  æœªæ‰¾åˆ° OPENAI_API_KEY ç¯å¢ƒå˜é‡")
        print("ğŸ’¡ è¯·è®¾ç½®ç¯å¢ƒå˜é‡: export OPENAI_API_KEY='your-api-key'")
        print("ğŸ”§ å°†ä½¿ç”¨Ollamaæœ¬åœ°æ¨¡å‹...")
    
    # åˆ›å»ºAI+MCPæ¼”ç¤ºå®ä¾‹
    ai_demo = AIMCPDemo(openai_api_key, ollama_url, ollama_model)
    
    try:
        # æ¼”ç¤ºAIåŠŸèƒ½
        await ai_demo.demonstrate_ai_capabilities()
        
        # æ¼”ç¤ºæœåŠ¡å™¨å¯åŠ¨
        await ai_demo.start_ai_server()
        
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºè¿è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # ç¡®ä¿AIå®¢æˆ·ç«¯è¢«æ­£ç¡®å…³é—­
        await ai_demo.close()
    
    print("\nğŸ‰ æ¼”ç¤ºå®Œæˆ!")
    print("\nğŸ’¡ å…³é”®è¦ç‚¹:")
    print("  - MCPå·¥å…·ä¸ºAIæ¨¡å‹æä¾›æ ‡å‡†åŒ–æ¥å£")
    print("  - AIæ¨¡å‹å¯ä»¥åŠ¨æ€é€‰æ‹©è°ƒç”¨å“ªä¸ªå·¥å…·")
    print("  - å·¥å…·è¿”å›ç»“æ„åŒ–æ•°æ®ä¾›AIåˆ†æ")
    print("  - æ”¯æŒAIæ¨¡å‹çš„åå¤„ç†å’Œåˆ†æ")
    print("  - æ”¯æŒOpenAIå’ŒOllamaä¸¤ç§AIæ¨¡å‹")
    print("  - æœ¬åœ°OllamaæœåŠ¡æä¾›ç¦»çº¿AIèƒ½åŠ›")


if __name__ == "__main__":
    asyncio.run(main())
